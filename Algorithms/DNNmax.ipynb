{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>summertime</th>\n",
       "      <th>temp</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>increase_stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>53.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>31.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>low_bike_demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>40.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>85.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>low_bike_demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>73.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>low_bike_demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>59.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>low_bike_demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>18.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>44.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>low_bike_demand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour_of_day  day_of_week  month  holiday  weekday  summertime  temp   dew  \\\n",
       "0            5            5      1        0        0           0  -7.2 -15.0   \n",
       "1           21            4      1        0        1           0  -1.3 -12.8   \n",
       "2           21            3      8        0        1           1  26.9  21.8   \n",
       "3            1            6      1        0        0           0   3.1  -4.0   \n",
       "4           17            0      3        0        1           0  11.7 -11.4   \n",
       "\n",
       "   humidity  precip  snow  snowdepth  windspeed  cloudcover  visibility  \\\n",
       "0     53.68     0.0     0        0.0       16.3        31.6        16.0   \n",
       "1     40.97     0.0     0        0.0       23.9        85.7        16.0   \n",
       "2     73.39     0.0     0        0.0        0.0        81.1        16.0   \n",
       "3     59.74     0.0     0        0.0       19.2         0.0        16.0   \n",
       "4     18.71     0.0     0        0.0       10.5        44.6        16.0   \n",
       "\n",
       "    increase_stock  \n",
       "0  low_bike_demand  \n",
       "1  low_bike_demand  \n",
       "2  low_bike_demand  \n",
       "3  low_bike_demand  \n",
       "4  low_bike_demand  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "file_path = 'training_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 编码目标变量\n",
    "le = LabelEncoder()\n",
    "data['increase_stock'] = le.fit_transform(data['increase_stock'])\n",
    "\n",
    "# 将数据集分割为特征和目标\n",
    "X = data.drop('increase_stock', axis=1)\n",
    "y = data['increase_stock']\n",
    "\n",
    "# 将数据分割为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# 定义一个简单的深度神经网络\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# 神经网络参数\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 转换为 PyTorch tensors\n",
    "X_train_torch = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "y_train_torch = torch.tensor(y_train.values.astype(np.int64))\n",
    "X_test_torch = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "y_test_torch = torch.tensor(y_test.values.astype(np.int64))\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 初始化网络和优化器\n",
    "model = SimpleDNN(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 评估模型性能\n",
    "model.eval()\n",
    "outputs = model(X_test_torch)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "accuracy_dnn = (predicted == y_test_torch).sum().item() / y_test_torch.size(0)\n",
    "\n",
    "# 将 DNN 模型的预测结果与其他模型的结果结合起来进行软投票\n",
    "# 注意: 这需要手动实现，因为 sklearn 的 VotingClassifier 不能直接集成 PyTorch 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1200)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "random_forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/anaconda3/envs/deeplearning/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/max/anaconda3/envs/deeplearning/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.special import softmax\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# 获取 sklearn 模型的预测概率\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lda.fit(X_train_scaled, y_train)\n",
    "qda.fit(X_train_scaled, y_train)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "prob_lr = lr.predict_proba(X_test_scaled)\n",
    "prob_lda = lda.predict_proba(X_test_scaled)\n",
    "prob_qda = qda.predict_proba(X_test_scaled)\n",
    "prob_knn = knn.predict_proba(X_test_scaled)\n",
    "prob_rf = random_forest.predict_proba(X_test_scaled)\n",
    "\n",
    "# 获取 DNN 模型的预测概率\n",
    "dnn_outputs = model(X_test_torch)\n",
    "prob_dnn = softmax(dnn_outputs.detach().numpy(), axis=1)\n",
    "\n",
    "# 计算所有模型预测概率的平均值\n",
    "average_probs = (prob_knn + prob_rf + prob_dnn)/3 #(prob_lr + prob_lda + prob_qda + prob_knn + prob_rf + prob_dnn) / 6\n",
    "\n",
    "# 选择具有最高平均概率的类别作为最终预测\n",
    "final_predictions = np.argmax(average_probs, axis=1)\n",
    "\n",
    "# 计算最终的准确率\n",
    "final_accuracy = np.mean(final_predictions == y_test)\n",
    "\n",
    "final_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/anaconda3/envs/deeplearning/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
